import streamlit as st
import cv2
import tempfile
import numpy as np
import time
from ultralytics import YOLO
from utils import save_for_retrain, init_recorders
from streamlit_drawable_canvas import st_canvas
from PIL import Image
from streamlit_autorefresh import st_autorefresh

# ‚ö†Ô∏è ƒë·∫∑t ngay sau import
st.set_page_config(page_title="Wood Defect Detection", layout="wide")

st.title("üîç Wood Defect Detection System")

# Load model
if "model_path" not in st.session_state:
    st.session_state["model_path"] = "models/best.pt"
model = YOLO(st.session_state["model_path"])


with st.sidebar:
    uploaded_model = st.file_uploader(
        "üîÑ Ch·ªçn file model m·ªõi",
        type=["pt", "onnx", "engine", "tflite", "mlmodel", "pb", "torchscript", "ncnn"],
        key="model_file_uploader",
        help="Limit 200MB per file ‚Ä¢ PT, ONNX, ENGINE, TFLITE, MLMODEL, PB, TORCHSCRIPT, NCNN"
    )
    st.markdown(
        "<div style='color:gray;font-size:13px;margin-top:-10px;'>"
        "Drag and drop file here<br>Limit 200MB per file ‚Ä¢ PT, ONNX, ENGINE, "
        "TFLITE, MLMODEL, PB, TORCHSCRIPT, NCNN"
        "</div>",
        unsafe_allow_html=True
    )

    if uploaded_model is not None:
        import tempfile, shutil
        temp_model_path = tempfile.NamedTemporaryFile(
            delete=False,
            suffix="." + uploaded_model.name.split(".")[-1]
        ).name
        with open(temp_model_path, "wb") as f:
            shutil.copyfileobj(uploaded_model, f)
        st.session_state["model_path"] = temp_model_path
        st.success(f"‚úÖ ƒê√£ ch·ªçn model: {uploaded_model.name}")


# Sidebar
conf = st.sidebar.slider("Confidence", 0.1, 1.0, 0.25, 0.05)

if "cameras" not in st.session_state:
    st.session_state["cameras"] = []
if "add_cam_mode" not in st.session_state:
    st.session_state["add_cam_mode"] = False
if "new_cam_type" not in st.session_state:
    st.session_state["new_cam_type"] = "USB"
if "new_cam_source" not in st.session_state:
    st.session_state["new_cam_source"] = 0

source = st.sidebar.radio("Ch·ªçn ngu·ªìn d·ªØ li·ªáu", ["Camera", "Upload ·∫¢nh", "Upload Video"])
# Camera Section - Refactored
# Camera Section - Fixed Version
if source == "Camera":
    st.header("üì∑ Camera Detection")
    
    # Initialize session states
    if "cameras" not in st.session_state:
        st.session_state["cameras"] = {}
    if "show_add_camera" not in st.session_state:
        st.session_state["show_add_camera"] = False
    if "recording_states" not in st.session_state:
        st.session_state["recording_states"] = {}
    if "camera_running" not in st.session_state:
        st.session_state["camera_running"] = {}
    
    # ‚úÖ Auto refresh nhanh h∆°n cho realtime
    st_autorefresh(interval=100, key="camera_refresh")  # 100ms thay v√¨ 1000ms
    
    # N√∫t th√™m camera
    if st.button("‚ûï Th√™m Camera", type="primary"):
        st.session_state["show_add_camera"] = True
    
    # Form th√™m camera
    if st.session_state["show_add_camera"]:
        with st.form("add_camera_form"):
            st.write("### üé• C·∫•u h√¨nh Camera m·ªõi")
            
            camera_name = st.text_input("T√™n camera:", value=f"Camera {len(st.session_state['cameras'])+1}")
            camera_type = st.radio("Lo·∫°i camera:", ["USB", "IP"], horizontal=True)
            
            if camera_type == "USB":
                camera_source = st.selectbox("USB Camera:", [0, 1, 2, 3, 4])
            else:
                camera_source = st.text_input("URL IP Camera:", 
                                            placeholder="rtsp://admin:password@192.168.1.100:554/stream")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.form_submit_button("‚úÖ X√°c nh·∫≠n", type="primary"):
                    # Test camera connection
                    with st.spinner("ƒêang test k·∫øt n·ªëi..."):
                        try:
                            test_cap = cv2.VideoCapture(camera_source)
                            if test_cap.isOpened():
                                ret, frame = test_cap.read()
                                test_cap.release()
                                
                                if ret:
                                    # T·∫°o camera m·ªõi
                                    camera_id = f"cam_{int(time.time())}"
                                    st.session_state["cameras"][camera_id] = {
                                        "name": camera_name,
                                        "type": camera_type,
                                        "source": camera_source,
                                        "cap": None,
                                        "status": "ready"  # ‚úÖ ƒê·ªïi t·ª´ "stopped" th√†nh "ready"
                                    }
                                    st.session_state["recording_states"][camera_id] = {
                                        "is_recording": False,
                                        "video_writer": None,
                                        "start_time": None
                                    }
                                    st.session_state["camera_running"][camera_id] = True  # ‚úÖ Auto start
                                    
                                    st.success(f"‚úÖ Camera {camera_name} ƒë√£ ƒë∆∞·ª£c th√™m v√† s·∫Ω b·∫Øt ƒë·∫ßu ngay!")
                                    st.session_state["show_add_camera"] = False
                                    time.sleep(1)
                                    st.rerun()
                                else:
                                    st.error("‚ùå Camera k·∫øt n·ªëi ƒë∆∞·ª£c nh∆∞ng kh√¥ng c√≥ t√≠n hi·ªáu!")
                            else:
                                st.error(f"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi camera: {camera_source}")
                        except Exception as e:
                            st.error(f"‚ùå L·ªói: {str(e)}")
            
            with col2:
                if st.form_submit_button("‚ùå H·ªßy"):
                    st.session_state["show_add_camera"] = False
                    st.rerun()
    
    # ‚úÖ Hi·ªÉn th·ªã cameras v·ªõi logic ƒë∆°n gi·∫£n h√≥a
    if st.session_state["cameras"]:
        st.markdown("---")
        
        # Grid layout cho cameras
        camera_ids = list(st.session_state["cameras"].keys())
        num_cols = min(len(camera_ids), 2)  # T·ªëi ƒëa 2 c·ªôt
        
        if num_cols > 0:
            cols = st.columns(num_cols)
            
            for idx, camera_id in enumerate(camera_ids):
                camera = st.session_state["cameras"][camera_id]
                col_idx = idx % num_cols
                
                with cols[col_idx]:
                    # Camera container
                    with st.container():
                        st.markdown(f"### üé¶ {camera['name']}")
                        
                        # Video frame placeholder
                        frame_placeholder = st.empty()
                        status_placeholder = st.empty()
                        
                        # ‚úÖ Kh·ªüi t·∫°o camera m·ªôt l·∫ßn v√† gi·ªØ k·∫øt n·ªëi
                        camera_should_run = st.session_state["camera_running"].get(camera_id, False)
                        
                        if camera_should_run:
                            # Kh·ªüi t·∫°o camera n·∫øu ch∆∞a c√≥
                            if camera["cap"] is None:
                                try:
                                    cap = cv2.VideoCapture(camera["source"])
                                    if cap.isOpened():
                                        # T·ªëi ∆∞u settings
                                        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                                        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                                        cap.set(cv2.CAP_PROP_FPS, 30)
                                        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                                        
                                        camera["cap"] = cap
                                        camera["status"] = "running"
                                    else:
                                        camera["status"] = "error"
                                        camera_should_run = False
                                        st.session_state["camera_running"][camera_id] = False
                                        status_placeholder.error("‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o camera")
                                except Exception as e:
                                    camera["status"] = "error"
                                    camera_should_run = False
                                    st.session_state["camera_running"][camera_id] = False
                                    status_placeholder.error(f"‚ùå L·ªói: {str(e)}")
                            
                            # ‚úÖ ƒê·ªçc v√† hi·ªÉn th·ªã frame li√™n t·ª•c
                            if camera["status"] == "running" and camera["cap"] is not None:
                                try:
                                    cap = camera["cap"]
                                    ret, frame = cap.read()
                                    
                                    if ret:
                                        # YOLO detection
                                        results = model.predict(
                                            frame, 
                                            conf=conf, 
                                            imgsz=640,
                                            verbose=False,
                                            device='cpu'
                                        )
                                        annotated = results[0].plot()
                                        
                                        # Hi·ªÉn th·ªã frame
                                        frame_placeholder.image(annotated, channels="BGR", use_column_width=True)
                                        
                                        # Recording logic
                                        recording_state = st.session_state["recording_states"][camera_id]
                                        if recording_state["is_recording"]:
                                            if recording_state["video_writer"] is not None:
                                                recording_state["video_writer"].write(annotated)
                                            
                                            # Hi·ªÉn th·ªã tr·∫°ng th√°i recording
                                            elapsed = int(time.time() - recording_state["start_time"])
                                            status_placeholder.success(f"üî¥ RECORDING - {elapsed}s - {time.strftime('%H:%M:%S')}")
                                        else:
                                            status_placeholder.success(f"üü¢ LIVE - {time.strftime('%H:%M:%S')}")
                                    
                                    else:
                                        frame_placeholder.warning("‚ö†Ô∏è Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame")
                                        status_placeholder.warning("No Signal")
                                        
                                except Exception as e:
                                    frame_placeholder.error(f"‚ùå L·ªói x·ª≠ l√Ω: {str(e)}")
                                    status_placeholder.error("Processing Error")
                            
                        else:
                            # Camera stopped
                            frame_placeholder.info("üì∑ Camera ƒë√£ d·ª´ng. Nh·∫•n 'Start' ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
                            status_placeholder.info("Camera Stopped")
                        
                        # ‚úÖ Control buttons ƒë∆°n gi·∫£n h√≥a
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            # Start/Stop camera
                            if not camera_should_run:
                                if st.button("‚ñ∂Ô∏è Start", key=f"start_{camera_id}"):
                                    st.session_state["camera_running"][camera_id] = True
                                    st.rerun()
                            else:
                                if st.button("‚è∏Ô∏è Stop", key=f"stop_{camera_id}"):
                                    # Stop camera
                                    if camera["cap"] is not None:
                                        camera["cap"].release()
                                        camera["cap"] = None
                                    
                                    # Stop recording n·∫øu ƒëang record
                                    recording_state = st.session_state["recording_states"][camera_id]
                                    if recording_state["is_recording"]:
                                        if recording_state["video_writer"] is not None:
                                            recording_state["video_writer"].release()
                                        recording_state["is_recording"] = False
                                        recording_state["video_writer"] = None
                                    
                                    st.session_state["camera_running"][camera_id] = False
                                    camera["status"] = "stopped"
                                    st.rerun()
                        
                        with col2:
                            # Record button
                            recording_state = st.session_state["recording_states"][camera_id]
                            if camera_should_run and not recording_state["is_recording"]:
                                if st.button("üî¥ Record", key=f"record_{camera_id}"):
                                    try:
                                        # T·∫°o video writer
                                        timestamp = time.strftime("%Y%m%d_%H%M%S")
                                        output_path = f"recordings/{camera['name']}_{timestamp}.mp4"
                                        
                                        # T·∫°o th∆∞ m·ª•c recordings n·∫øu ch∆∞a c√≥
                                        import os
                                        os.makedirs("recordings", exist_ok=True)
                                        
                                        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                                        video_writer = cv2.VideoWriter(output_path, fourcc, 20.0, (640, 480))
                                        
                                        recording_state["is_recording"] = True
                                        recording_state["video_writer"] = video_writer
                                        recording_state["start_time"] = time.time()
                                        recording_state["output_path"] = output_path
                                        
                                        st.success(f"üî¥ B·∫Øt ƒë·∫ßu record: {output_path}")
                                        time.sleep(0.5)
                                        st.rerun()
                                        
                                    except Exception as e:
                                        st.error(f"‚ùå L·ªói record: {str(e)}")
                            elif recording_state["is_recording"]:
                                if st.button("‚èπÔ∏è Stop Rec", key=f"stop_record_{camera_id}"):
                                    try:
                                        if recording_state["video_writer"] is not None:
                                            recording_state["video_writer"].release()
                                        
                                        recording_state["is_recording"] = False
                                        recording_state["video_writer"] = None
                                        
                                        st.success(f"‚úÖ ƒê√£ l∆∞u: {recording_state.get('output_path', 'video')}")
                                        time.sleep(0.5)
                                        st.rerun()
                                        
                                    except Exception as e:
                                        st.error(f"‚ùå L·ªói d·ª´ng record: {str(e)}")
                        
                        with col3:
                            # Restart camera
                            if st.button("üîÑ Restart", key=f"restart_{camera_id}"):
                                try:
                                    # Release old camera
                                    if camera["cap"] is not None:
                                        camera["cap"].release()
                                        camera["cap"] = None
                                    
                                    # Stop recording n·∫øu ƒëang record
                                    if recording_state["is_recording"]:
                                        if recording_state["video_writer"] is not None:
                                            recording_state["video_writer"].release()
                                        recording_state["is_recording"] = False
                                        recording_state["video_writer"] = None
                                    
                                    camera["status"] = "ready"
                                    st.session_state["camera_running"][camera_id] = True  # Auto start sau restart
                                    st.success("üîÑ Camera restarted!")
                                    time.sleep(0.5)
                                    st.rerun()
                                    
                                except Exception as e:
                                    st.error(f"‚ùå L·ªói restart: {str(e)}")
                        
                        with col4:
                            # Delete camera
                            if st.button("üóëÔ∏è X√≥a", key=f"delete_{camera_id}"):
                                try:
                                    # Cleanup camera
                                    if camera["cap"] is not None:
                                        camera["cap"].release()
                                    
                                    # Stop recording
                                    if recording_state["is_recording"]:
                                        if recording_state["video_writer"] is not None:
                                            recording_state["video_writer"].release()
                                    
                                    # Remove from session state
                                    del st.session_state["cameras"][camera_id]
                                    del st.session_state["recording_states"][camera_id]
                                    if camera_id in st.session_state["camera_running"]:
                                        del st.session_state["camera_running"][camera_id]
                                    
                                    st.success(f"‚úÖ ƒê√£ x√≥a camera {camera['name']}")
                                    time.sleep(0.5)
                                    st.rerun()
                                    
                                except Exception as e:
                                    st.error(f"‚ùå L·ªói x√≥a camera: {str(e)}")
                        
                        st.markdown("---")
    
    else:
        # No cameras message
        st.info("üì∑ Ch∆∞a c√≥ camera n√†o. Nh·∫•n **'‚ûï Th√™m Camera'** ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
        st.markdown("""
        ### üí° H∆∞·ªõng d·∫´n:
        - **USB Camera**: Ch·ªçn index t·ª´ 0-4 (th∆∞·ªùng l√† 0 ho·∫∑c 1)
        - **IP Camera**: Nh·∫≠p URL ƒë·∫ßy ƒë·ªß nh∆∞ `rtsp://admin:123456@192.168.1.100:554/stream`
        - Sau khi th√™m camera, h·ªá th·ªëng s·∫Ω **t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu** detection realtime
        - S·ª≠ d·ª•ng c√°c n√∫t **Start/Stop**, **Record**, **Restart**, **X√≥a** ƒë·ªÉ ƒëi·ªÅu khi·ªÉn camera
        """)

    # Cleanup khi tho√°t
    def cleanup_cameras():
        """Cleanup t·∫•t c·∫£ cameras khi tho√°t"""
        if "cameras" in st.session_state:
            for camera_id, camera in st.session_state["cameras"].items():
                if camera.get("cap") is not None:
                    camera["cap"].release()
        
        if "recording_states" in st.session_state:
            for camera_id, recording_state in st.session_state["recording_states"].items():
                if recording_state.get("video_writer") is not None:
                    recording_state["video_writer"].release()
    
    # Register cleanup
    import atexit
    atexit.register(cleanup_cameras)

# --- Upload ·∫¢nh ---
elif source == "Upload ·∫¢nh":
    uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, 1)
        results = model.predict(img, conf=conf, imgsz=640, verbose=False)
        annotated = results[0].plot()

        st.image(annotated, channels="BGR", width=640, caption="K·∫øt qu·∫£ detect")

        # Feedback
        st.subheader("üìã ƒê√°nh gi√° k·∫øt qu·∫£")
        correct = st.radio("K·∫øt qu·∫£ detect c√≥ ƒë√∫ng kh√¥ng?", ["ƒê√∫ng", "Sai"], horizontal=True)

        if correct == "Sai":
            st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn nh√£n v√† v·∫Ω nhi·ªÅu bbox (m·ªói bbox m·ªôt nh√£n, m√†u kh√°c nhau)")
            classes = model.names
            class_names = list(classes.values())
            # G√°n m√†u cho t·ª´ng nh√£n
            color_palette = ["#FF0000", "#00FF00", "#0000FF", "#FFA500", "#800080", "#00FFFF", "#FFC0CB", "#FFFF00"]
            color_map = {name: color_palette[i % len(color_palette)] for i, name in enumerate(class_names)}
            # Ch·ªçn nh√£n hi·ªán t·∫°i
            true_label = st.selectbox("Ch·ªçn nh√£n hi·ªán t·∫°i ƒë·ªÉ v·∫Ω bbox", options=class_names)
            # V·∫Ω bbox m·ªõi tr√™n ·∫£nh g·ªëc
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img_pil = Image.fromarray(img_rgb)
            canvas_result = st_canvas(
                fill_color=color_map[true_label] + "80",  # alpha
                stroke_width=3,
                stroke_color=color_map[true_label],
                background_image=img_pil,
                update_streamlit=True,
                height=img.shape[0],
                width=img.shape[1],
                drawing_mode="rect",
                key="canvas_multi_bbox"
            )
            if st.button("üíæ L∆∞u c√°c bbox"):
                if canvas_result.json_data and len(canvas_result.json_data["objects"]) > 0:
                    labels = []
                    objects = canvas_result.json_data["objects"]
                    # √Ånh x·∫° m√†u v·ªÅ nh√£n
                    color_to_class = {v.lower(): k for k, v in color_map.items()}
                    for obj in objects:
                        left = obj["left"]
                        top = obj["top"]
                        width_box = obj["width"]
                        height_box = obj["height"]
                        # Convert sang YOLO
                        x_center = (left + width_box / 2) / img.shape[1]
                        y_center = (top + height_box / 2) / img.shape[0]
                        w = width_box / img.shape[1]
                        h = height_box / img.shape[0]
                        # L·∫•y nh√£n t·ª´ m√†u v·∫Ω
                        stroke = obj.get("stroke", "#FF0000").lower()
                        # Lo·∫°i b·ªè alpha n·∫øu c√≥
                        if len(stroke) > 7:
                            stroke = stroke[:7]
                        cls_name = color_to_class.get(stroke, class_names[0])
                        cls_id = class_names.index(cls_name)
                        labels.append((cls_id, x_center, y_center, w, h))
                    img_path, label_path = save_for_retrain(img, labels=labels, class_names=class_names)
                    st.success(f"‚úÖ ƒê√£ l∆∞u {len(labels)} bbox v√†o {label_path}")
                else:
                    st.error("‚ùå B·∫°n c·∫ßn v·∫Ω √≠t nh·∫•t m·ªôt bbox tr∆∞·ªõc khi l∆∞u!")


# --- Upload Video ---
# --- Upload Video ---
elif source == "Upload Video":
    uploaded_video = st.file_uploader("Ch·ªçn video", type=["mp4", "avi", "mov", "mkv"])
    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        cap = cv2.VideoCapture(tfile.name)

        current_frame = None
        stop_frame = None

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            results = model.predict(frame, conf=conf, imgsz=640, verbose=False)
            annotated = results[0].plot()

            # frame_placeholder.image(annotated, channels="BGR", width=640)
            # status_placeholder.write(f"üé• ƒêang x·ª≠ l√Ω video... {time.strftime('%H:%M:%S')}")
            current_frame = frame.copy()

            # N√∫t ch·ª•p ·∫£nh t·∫°i frame hi·ªán t·∫°i
            if st.button("üì∏ Ch·ª•p frame n√†y"):
                stop_frame = current_frame
                break

        cap.release()

        # N·∫øu user ch·ª•p l·∫°i frame
        if stop_frame is not None:
            st.subheader("üñº Frame ƒë∆∞·ª£c ch·ª•p t·ª´ video")
            results = model.predict(stop_frame, conf=conf, imgsz=640, verbose=False)
            annotated = results[0].plot()

            st.image(annotated, channels="BGR", width=640, caption="K·∫øt qu·∫£ detect")

            correct = st.radio("K·∫øt qu·∫£ detect c√≥ ƒë√∫ng kh√¥ng?", ["ƒê√∫ng", "Sai"], horizontal=True)
            if correct == "Sai":
                st.warning("‚ö†Ô∏è Ch·ªçn nh√£n ƒë√∫ng v√† v·∫Ω l·∫°i bbox tr√™n frame")

                classes = model.names
                true_label = st.selectbox("Ch·ªçn nh√£n ƒë√∫ng", options=list(classes.values()))

                from streamlit_drawable_canvas import st_canvas
                from PIL import Image
                img_rgb = cv2.cvtColor(stop_frame, cv2.COLOR_BGR2RGB)
                img_pil = Image.fromarray(img_rgb)

                canvas_result = st_canvas(
                    fill_color="rgba(255, 0, 0, 0.3)",
                    stroke_width=3,
                    stroke_color="#FF0000",
                    background_image=img_pil,
                    update_streamlit=True,
                    height=stop_frame.shape[0],
                    width=stop_frame.shape[1],
                    drawing_mode="rect",
                    key="canvas_video_bbox"
                )

                if st.button("üíæ L∆∞u frame sai nh√£n"):
                    bbox = None
                    if canvas_result.json_data and len(canvas_result.json_data["objects"]) > 0:
                        obj = canvas_result.json_data["objects"][0]
                        left = obj["left"]
                        top = obj["top"]
                        width_box = obj["width"]
                        height_box = obj["height"]

                        # Chuy·ªÉn sang YOLO format
                        x_center = (left + width_box / 2) / stop_frame.shape[1]
                        y_center = (top + height_box / 2) / stop_frame.shape[0]
                        w = width_box / stop_frame.shape[1]
                        h = height_box / stop_frame.shape[0]
                        bbox = (x_center, y_center, w, h)

                    if bbox:
                        img_path, label_path = save_for_retrain(stop_frame, true_label, model.names, bbox)
                        st.success(f"‚úÖ ƒê√£ l∆∞u v√†o {img_path}, {label_path}")
                    else:
                        st.error("‚ùå B·∫°n c·∫ßn v·∫Ω m·ªôt bbox tr∆∞·ªõc khi l∆∞u!")
